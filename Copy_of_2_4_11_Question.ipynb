{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of 2-4-11-Question.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithinpuravankara/TinyML/blob/main/Copy_of_2_4_11_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktqTCGHJw-ws"
      },
      "source": [
        "# Bean Disease Classifier\n",
        "For this assignment you'll take what you've learned so far and build a classifier for bean disease. You'll be provided with training and validation data based on 224x224 pixel color images taken of bean plants in Uganda. These images show healthy bean leaves as well as 2 types of common disease: bean rust and angular leaf spots. Your job will be to build a neural network that can tell the difference between the healthy and diseased leaves.\n",
        "\n",
        "We start by setting up the problem for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmnkg6vGbX1t"
      },
      "source": [
        "# Do not change this code\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njf4YhwFb6hW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5728b56-f119-439e-89a2-b78f6405845b"
      },
      "source": [
        "# Do not change this code\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/train.zip \\\n",
        "    -O /tmp/train.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/validation.zip \\\n",
        "    -O /tmp/validation.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/ibeans/test.zip \\\n",
        "    -O /tmp/test.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-04 17:41:16--  https://storage.googleapis.com/ibeans/train.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.136.128, 209.85.200.128, 108.177.112.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.136.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143812152 (137M) [application/zip]\n",
            "Saving to: ‘/tmp/train.zip’\n",
            "\n",
            "/tmp/train.zip      100%[===================>] 137.15M   116MB/s    in 1.2s    \n",
            "\n",
            "2021-11-04 17:41:17 (116 MB/s) - ‘/tmp/train.zip’ saved [143812152/143812152]\n",
            "\n",
            "--2021-11-04 17:41:17--  https://storage.googleapis.com/ibeans/validation.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.74.128, 209.85.145.128, 172.217.219.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.74.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18504213 (18M) [application/zip]\n",
            "Saving to: ‘/tmp/validation.zip’\n",
            "\n",
            "/tmp/validation.zip 100%[===================>]  17.65M  54.1MB/s    in 0.3s    \n",
            "\n",
            "2021-11-04 17:41:18 (54.1 MB/s) - ‘/tmp/validation.zip’ saved [18504213/18504213]\n",
            "\n",
            "--2021-11-04 17:41:18--  https://storage.googleapis.com/ibeans/test.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.202.128, 74.125.69.128, 173.194.194.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17708541 (17M) [application/zip]\n",
            "Saving to: ‘/tmp/test.zip’\n",
            "\n",
            "/tmp/test.zip       100%[===================>]  16.89M  97.6MB/s    in 0.2s    \n",
            "\n",
            "2021-11-04 17:41:18 (97.6 MB/s) - ‘/tmp/test.zip’ saved [17708541/17708541]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KscpTrSWcK1T"
      },
      "source": [
        "# Do not change this code\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/train.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/validation.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "local_zip = '/tmp/test.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/test')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPxygK9rCXu5"
      },
      "source": [
        "Now you need to define a generator to process the data we have loaded in Colab so that our model can use it for training. As we showed in the previous video you'll first have to define an ```ImageDataGenerator``` and then flow the data into it.\n",
        "\n",
        "*A hint: You don't want abnormal data!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCiSd248caB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06910cd-da3a-4549-dacc-09b8241823aa"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "TRAIN_DIRECTORY_LOCATION = os.path.join('/tmp/train')\n",
        "VAL_DIRECTORY_LOCATION = os.path.join('/tmp/validation')\n",
        "TARGET_SIZE = (224,224)\n",
        "CLASS_MODE = 'categorical'\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,  \n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VAL_DIRECTORY_LOCATION,\n",
        "    target_size = TARGET_SIZE,  \n",
        "    batch_size = 128,\n",
        "    class_mode = CLASS_MODE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1034 images belonging to 3 classes.\n",
            "Found 133 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tO7XZAeCXu6"
      },
      "source": [
        "Now its your turn to define a model to learn this data. \n",
        "\n",
        "*A hint: Like with the CIFAR-10 assignment, your model may want to learn some high level features and then classify them. This time it may help to make the model a little wider at times.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrJt6YSDcqjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d46623-5a53-48cf-b5f0-aa03bffb6506"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='relu'),\n",
        "])\n",
        "\n",
        "# This will print a summary of your model when you're done!\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 222, 222, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 111, 111, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 109, 109, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3277312   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 3,802,019\n",
            "Trainable params: 3,802,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHnsqGrxCXu7"
      },
      "source": [
        "Then you'll need to pick an appropriate loss function and optimizer.\n",
        "\n",
        "*A hint: remember we are classifying again.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nST6CyvCcy-2"
      },
      "source": [
        "LOSS_FUNCTION = 'categorical_crossentropy'\n",
        "OPTIMIZER = 'adam'\n",
        "\n",
        "model.compile(\n",
        "    loss = LOSS_FUNCTION,\n",
        "    optimizer = OPTIMIZER,\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDlMu7uyCXu7"
      },
      "source": [
        "Finally select the number of epochs you'd like to train for and train your model!\n",
        "\n",
        "*A hint: something in the low tens is a good place to start*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3iK9LX9deu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "outputId": "7b0878df-06fd-499e-abb0-933aefd84040"
      },
      "source": [
        "NUM_EPOCHS = 20\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator, \n",
        "      epochs = NUM_EPOCHS,\n",
        "      verbose = 1,\n",
        "      validation_data = validation_generator)\n",
        "\n",
        "# summarize history for accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.xlim([0,NUM_EPOCHS])\n",
        "plt.ylim([0.4,1.0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "9/9 [==============================] - 54s 2s/step - loss: 10.3028 - accuracy: 0.3201 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 19s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 19s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 19s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 19s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 19s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 19s 2s/step - loss: 10.8026 - accuracy: 0.3298 - val_loss: 10.7858 - val_accuracy: 0.3308\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}